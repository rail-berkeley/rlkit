{
  "add_env_demos": true,
  "add_env_offpolicy_data": true,
  "algo_kwargs": {
    "batch_size": 5,
    "min_num_steps_before_training": 10,
    "num_epochs": 5,
    "num_eval_steps_per_epoch": 100,
    "num_expl_steps_per_train_loop": 100,
    "num_trains_per_train_loop": 10
  },
  "algorithm": "AWAC",
  "collection_mode": "batch",
  "debug": true,
  "env_demo_path": {
    "is_demo": true,
    "obs_dict": true,
    "path": "demos/icml2020/hand/pen2_sparse.npy"
  },
  "env_id": "pen-binary-v0",
  "env_offpolicy_data_path": {
    "is_demo": false,
    "obs_dict": false,
    "path": "demos/icml2020/hand/pen_bc_sparse4.npy",
    "train_split": 0.9
  },
  "exp_id": 0,
  "exp_name": "references/awac/hand/awac1",
  "load_demos": true,
  "logger_config": {
    "run_id": 0,
    "snapshot_gap": 100,
    "snapshot_mode": "gap"
  },
  "max_path_length": 200,
  "normalize_env": false,
  "path_loader_class": {
    "$class": "rlkit.demos.source.dict_to_mdp_path_loader.DictToMDPPathLoader"
  },
  "path_loader_kwargs": {
    "demo_paths": [],
    "obs_key": "state_observation"
  },
  "policy_class": {
    "$class": "rlkit.torch.sac.policies.gaussian_policy.GaussianPolicy"
  },
  "policy_kwargs": {
    "hidden_sizes": [
      256,
      256
    ],
    "max_log_std": 0,
    "min_log_std": -6,
    "std_architecture": "values"
  },
  "pretrain_policy": true,
  "pretrain_rl": true,
  "qf_kwargs": {
    "hidden_sizes": [
      256,
      256
    ],
    "output_activation": {
      "$function": "rlkit.torch.networks.basic.Clamp"
    }
  },
  "replay_buffer_size": 1000000,
  "run_id": 0,
  "seed": "0",
  "seedid": 0,
  "sparse_reward": true,
  "trainer_kwargs": {
    "alpha": 0,
    "awr_min_q": true,
    "awr_use_mle_for_vf": true,
    "awr_weight": 1.0,
    "bc_num_pretrain_steps": 0,
    "bc_weight": 0.0,
    "beta": 0.5,
    "clip_score": 0.5,
    "compute_bc": false,
    "discount": 0.99,
    "policy_lr": 0.0003,
    "policy_weight_decay": 0.0001,
    "q_num_pretrain1_steps": 0,
    "q_num_pretrain2_steps": 10,
    "q_weight_decay": 0,
    "qf_lr": 0.0003,
    "reparam_weight": 0.0,
    "reward_scale": 1,
    "reward_transform_kwargs": null,
    "rl_weight": 1.0,
    "soft_target_tau": 0.005,
    "target_update_period": 1,
    "terminal_transform_kwargs": {
      "b": 0,
      "m": 0
    },
    "use_automatic_entropy_tuning": false,
    "use_awr_update": true,
    "use_reparam_update": false
  },
  "trial_name": "id0",
  "unique_id": "c7763e50-2054-4f0c-a288-addb1e964fac",
  "version": "normal"
}