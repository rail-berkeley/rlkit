diff --git a/rlkit/scripts/__init__.py b/rlkit/scripts/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/rlkit/scripts/run_experiment_from_doodad.py b/rlkit/scripts/run_experiment_from_doodad.py
new file mode 100644
index 0000000..1e21c25
--- /dev/null
+++ b/rlkit/scripts/run_experiment_from_doodad.py
@@ -0,0 +1,43 @@
+import doodad as dd
+from rlkit.launchers.launcher_util import run_experiment_here
+import torch.multiprocessing as mp
+
+if __name__ == "__main__":
+    import matplotlib
+    matplotlib.use('agg')
+
+    mp.set_start_method('forkserver')
+    args_dict = dd.get_args()
+    method_call = args_dict['method_call']
+    run_experiment_kwargs = args_dict['run_experiment_kwargs']
+    output_dir = args_dict['output_dir']
+    run_mode = args_dict.get('mode', None)
+    if run_mode and run_mode in ['slurm_singularity', 'sss']:
+        import os
+        run_experiment_kwargs['variant']['slurm-job-id'] = os.environ.get(
+            'SLURM_JOB_ID', None
+        )
+    if run_mode and run_mode == 'ec2':
+        try:
+            import urllib.request
+            instance_id = urllib.request.urlopen(
+                'http://169.254.169.254/latest/meta-data/instance-id'
+            ).read().decode()
+            run_experiment_kwargs['variant']['EC2_instance_id'] = instance_id
+        except Exception as e:
+            print("Could not get instance ID. Error was...")
+            print(e)
+    if run_mode and (run_mode == 'ec2' or run_mode == 'gcp'):
+        # Do this in case base_log_dir was already set
+        run_experiment_kwargs['base_log_dir'] = output_dir
+        run_experiment_here(
+            method_call,
+            include_exp_prefix_sub_dir=False,
+            **run_experiment_kwargs
+        )
+    else:
+        run_experiment_here(
+            method_call,
+            log_dir=output_dir,
+            **run_experiment_kwargs
+        )
\ No newline at end of file
diff --git a/rlkit/scripts/sim_goal_conditioned_policy.py b/rlkit/scripts/sim_goal_conditioned_policy.py
new file mode 100644
index 0000000..70a48ca
--- /dev/null
+++ b/rlkit/scripts/sim_goal_conditioned_policy.py
@@ -0,0 +1,62 @@
+import argparse
+import pickle
+
+from rlkit.core import logger
+from rlkit.samplers.rollout_functions import multitask_rollout
+from rlkit.torch import pytorch_util as ptu
+from rlkit.envs.vae_wrapper import VAEWrappedEnv
+
+
+def simulate_policy(args):
+    if args.pause:
+        import ipdb; ipdb.set_trace()
+    data = pickle.load(open(args.file, "rb"))
+    policy = data['policy']
+    env = data['env']
+    print("Policy and environment loaded")
+    if args.gpu:
+        ptu.set_gpu_mode(True)
+        policy.to(ptu.device)
+    if isinstance(env, VAEWrappedEnv):
+        env.mode(args.mode)
+    if args.enable_render or hasattr(env, 'enable_render'):
+        # some environments need to be reconfigured for visualization
+        env.enable_render()
+    policy.train(False)
+    paths = []
+    while True:
+        paths.append(multitask_rollout(
+            env,
+            policy,
+            max_path_length=args.H,
+            animated=not args.hide,
+            observation_key='observation',
+            desired_goal_key='desired_goal',
+        ))
+        if hasattr(env, "log_diagnostics"):
+            env.log_diagnostics(paths)
+        if hasattr(env, "get_diagnostics"):
+            for k, v in env.get_diagnostics(paths).items():
+                logger.record_tabular(k, v)
+        logger.dump_tabular()
+
+
+if __name__ == "__main__":
+
+    parser = argparse.ArgumentParser()
+    parser.add_argument('file', type=str,
+                        help='path to the snapshot file')
+    parser.add_argument('--H', type=int, default=300,
+                        help='Max length of rollout')
+    parser.add_argument('--speedup', type=float, default=10,
+                        help='Speedup')
+    parser.add_argument('--mode', default='video_env', type=str,
+                        help='env mode')
+    parser.add_argument('--gpu', action='store_true')
+    parser.add_argument('--pause', action='store_true')
+    parser.add_argument('--enable_render', action='store_true')
+    parser.add_argument('--multitaskpause', action='store_true')
+    parser.add_argument('--hide', action='store_true')
+    args = parser.parse_args()
+
+    simulate_policy(args)
diff --git a/rlkit/scripts/sim_policy.py b/rlkit/scripts/sim_policy.py
new file mode 100644
index 0000000..89baf6f
--- /dev/null
+++ b/rlkit/scripts/sim_policy.py
@@ -0,0 +1,43 @@
+from rlkit.samplers.util import rollout
+from rlkit.torch.core import PyTorchModule
+from rlkit.torch.pytorch_util import set_gpu_mode
+import argparse
+import joblib
+import uuid
+from rlkit.core import logger
+
+filename = str(uuid.uuid4())
+
+
+def simulate_policy(args):
+    data = joblib.load(args.file)
+    policy = data['policy']
+    env = data['env']
+    print("Policy loaded")
+    if args.gpu:
+        set_gpu_mode(True)
+        policy.cuda()
+    if isinstance(policy, PyTorchModule):
+        policy.train(False)
+    while True:
+        path = rollout(
+            env,
+            policy,
+            max_path_length=args.H,
+            animated=True,
+        )
+        if hasattr(env, "log_diagnostics"):
+            env.log_diagnostics([path])
+        logger.dump_tabular()
+
+
+if __name__ == "__main__":
+    parser = argparse.ArgumentParser()
+    parser.add_argument('file', type=str,
+                        help='path to the snapshot file')
+    parser.add_argument('--H', type=int, default=300,
+                        help='Max length of rollout')
+    parser.add_argument('--gpu', action='store_true')
+    args = parser.parse_args()
+
+    simulate_policy(args)
diff --git a/rlkit/scripts/sim_tdm_policy.py b/rlkit/scripts/sim_tdm_policy.py
new file mode 100644
index 0000000..d7b2272
--- /dev/null
+++ b/rlkit/scripts/sim_tdm_policy.py
@@ -0,0 +1,64 @@
+import argparse
+import json
+
+import joblib
+from pathlib import Path
+
+import rlkit.torch.pytorch_util as ptu
+from rlkit.core.eval_util import get_generic_path_information
+from rlkit.torch.tdm.sampling import multitask_rollout
+from rlkit.core import logger
+if __name__ == "__main__":
+
+    parser = argparse.ArgumentParser()
+    parser.add_argument('file', type=str, help='path to the snapshot file')
+    parser.add_argument('--H', type=int, default=300,
+                        help='Max length of rollout')
+    parser.add_argument('--nrolls', type=int, default=1,
+                        help='Number of rollout per eval')
+    parser.add_argument('--mtau', type=float, help='Max tau value')
+    parser.add_argument('--gpu', action='store_true')
+    parser.add_argument('--hide', action='store_true')
+    args = parser.parse_args()
+
+    data = joblib.load(args.file)
+    if args.mtau is None:
+        # Load max tau from variant.json file
+        variant_path = Path(args.file).parents[0] / 'variant.json'
+        variant = json.load(variant_path.open())
+        try:
+            max_tau = variant['tdm_kwargs']['max_tau']
+            print("Max tau read from variant: {}".format(max_tau))
+        except KeyError:
+            print("Defaulting max tau to 0.")
+            max_tau = 0
+    else:
+        max_tau = args.mtau
+
+    env = data['env']
+    policy = data['policy']
+    policy.train(False)
+
+    if args.gpu:
+        ptu.set_gpu_mode(True)
+        policy.cuda()
+
+    while True:
+        paths = []
+        for _ in range(args.nrolls):
+            goal = env.sample_goal_for_rollout()
+            path = multitask_rollout(
+                env,
+                policy,
+                init_tau=max_tau,
+                goal=goal,
+                max_path_length=args.H,
+                animated=not args.hide,
+                cycle_tau=True,
+                decrement_tau=True,
+            )
+            paths.append(path)
+        env.log_diagnostics(paths)
+        for key, value in get_generic_path_information(paths).items():
+            logger.record_tabular(key, value)
+        logger.dump_tabular()
diff --git a/scripts/run_experiment_from_doodad.py b/scripts/run_experiment_from_doodad.py
deleted file mode 100644
index 1e21c25..0000000
--- a/scripts/run_experiment_from_doodad.py
+++ /dev/null
@@ -1,43 +0,0 @@
-import doodad as dd
-from rlkit.launchers.launcher_util import run_experiment_here
-import torch.multiprocessing as mp
-
-if __name__ == "__main__":
-    import matplotlib
-    matplotlib.use('agg')
-
-    mp.set_start_method('forkserver')
-    args_dict = dd.get_args()
-    method_call = args_dict['method_call']
-    run_experiment_kwargs = args_dict['run_experiment_kwargs']
-    output_dir = args_dict['output_dir']
-    run_mode = args_dict.get('mode', None)
-    if run_mode and run_mode in ['slurm_singularity', 'sss']:
-        import os
-        run_experiment_kwargs['variant']['slurm-job-id'] = os.environ.get(
-            'SLURM_JOB_ID', None
-        )
-    if run_mode and run_mode == 'ec2':
-        try:
-            import urllib.request
-            instance_id = urllib.request.urlopen(
-                'http://169.254.169.254/latest/meta-data/instance-id'
-            ).read().decode()
-            run_experiment_kwargs['variant']['EC2_instance_id'] = instance_id
-        except Exception as e:
-            print("Could not get instance ID. Error was...")
-            print(e)
-    if run_mode and (run_mode == 'ec2' or run_mode == 'gcp'):
-        # Do this in case base_log_dir was already set
-        run_experiment_kwargs['base_log_dir'] = output_dir
-        run_experiment_here(
-            method_call,
-            include_exp_prefix_sub_dir=False,
-            **run_experiment_kwargs
-        )
-    else:
-        run_experiment_here(
-            method_call,
-            log_dir=output_dir,
-            **run_experiment_kwargs
-        )
\ No newline at end of file
diff --git a/scripts/sim_goal_conditioned_policy.py b/scripts/sim_goal_conditioned_policy.py
deleted file mode 100644
index 70a48ca..0000000
--- a/scripts/sim_goal_conditioned_policy.py
+++ /dev/null
@@ -1,62 +0,0 @@
-import argparse
-import pickle
-
-from rlkit.core import logger
-from rlkit.samplers.rollout_functions import multitask_rollout
-from rlkit.torch import pytorch_util as ptu
-from rlkit.envs.vae_wrapper import VAEWrappedEnv
-
-
-def simulate_policy(args):
-    if args.pause:
-        import ipdb; ipdb.set_trace()
-    data = pickle.load(open(args.file, "rb"))
-    policy = data['policy']
-    env = data['env']
-    print("Policy and environment loaded")
-    if args.gpu:
-        ptu.set_gpu_mode(True)
-        policy.to(ptu.device)
-    if isinstance(env, VAEWrappedEnv):
-        env.mode(args.mode)
-    if args.enable_render or hasattr(env, 'enable_render'):
-        # some environments need to be reconfigured for visualization
-        env.enable_render()
-    policy.train(False)
-    paths = []
-    while True:
-        paths.append(multitask_rollout(
-            env,
-            policy,
-            max_path_length=args.H,
-            animated=not args.hide,
-            observation_key='observation',
-            desired_goal_key='desired_goal',
-        ))
-        if hasattr(env, "log_diagnostics"):
-            env.log_diagnostics(paths)
-        if hasattr(env, "get_diagnostics"):
-            for k, v in env.get_diagnostics(paths).items():
-                logger.record_tabular(k, v)
-        logger.dump_tabular()
-
-
-if __name__ == "__main__":
-
-    parser = argparse.ArgumentParser()
-    parser.add_argument('file', type=str,
-                        help='path to the snapshot file')
-    parser.add_argument('--H', type=int, default=300,
-                        help='Max length of rollout')
-    parser.add_argument('--speedup', type=float, default=10,
-                        help='Speedup')
-    parser.add_argument('--mode', default='video_env', type=str,
-                        help='env mode')
-    parser.add_argument('--gpu', action='store_true')
-    parser.add_argument('--pause', action='store_true')
-    parser.add_argument('--enable_render', action='store_true')
-    parser.add_argument('--multitaskpause', action='store_true')
-    parser.add_argument('--hide', action='store_true')
-    args = parser.parse_args()
-
-    simulate_policy(args)
diff --git a/scripts/sim_policy.py b/scripts/sim_policy.py
deleted file mode 100644
index 89baf6f..0000000
--- a/scripts/sim_policy.py
+++ /dev/null
@@ -1,43 +0,0 @@
-from rlkit.samplers.util import rollout
-from rlkit.torch.core import PyTorchModule
-from rlkit.torch.pytorch_util import set_gpu_mode
-import argparse
-import joblib
-import uuid
-from rlkit.core import logger
-
-filename = str(uuid.uuid4())
-
-
-def simulate_policy(args):
-    data = joblib.load(args.file)
-    policy = data['policy']
-    env = data['env']
-    print("Policy loaded")
-    if args.gpu:
-        set_gpu_mode(True)
-        policy.cuda()
-    if isinstance(policy, PyTorchModule):
-        policy.train(False)
-    while True:
-        path = rollout(
-            env,
-            policy,
-            max_path_length=args.H,
-            animated=True,
-        )
-        if hasattr(env, "log_diagnostics"):
-            env.log_diagnostics([path])
-        logger.dump_tabular()
-
-
-if __name__ == "__main__":
-    parser = argparse.ArgumentParser()
-    parser.add_argument('file', type=str,
-                        help='path to the snapshot file')
-    parser.add_argument('--H', type=int, default=300,
-                        help='Max length of rollout')
-    parser.add_argument('--gpu', action='store_true')
-    args = parser.parse_args()
-
-    simulate_policy(args)
diff --git a/scripts/sim_tdm_policy.py b/scripts/sim_tdm_policy.py
deleted file mode 100644
index d7b2272..0000000
--- a/scripts/sim_tdm_policy.py
+++ /dev/null
@@ -1,64 +0,0 @@
-import argparse
-import json
-
-import joblib
-from pathlib import Path
-
-import rlkit.torch.pytorch_util as ptu
-from rlkit.core.eval_util import get_generic_path_information
-from rlkit.torch.tdm.sampling import multitask_rollout
-from rlkit.core import logger
-if __name__ == "__main__":
-
-    parser = argparse.ArgumentParser()
-    parser.add_argument('file', type=str, help='path to the snapshot file')
-    parser.add_argument('--H', type=int, default=300,
-                        help='Max length of rollout')
-    parser.add_argument('--nrolls', type=int, default=1,
-                        help='Number of rollout per eval')
-    parser.add_argument('--mtau', type=float, help='Max tau value')
-    parser.add_argument('--gpu', action='store_true')
-    parser.add_argument('--hide', action='store_true')
-    args = parser.parse_args()
-
-    data = joblib.load(args.file)
-    if args.mtau is None:
-        # Load max tau from variant.json file
-        variant_path = Path(args.file).parents[0] / 'variant.json'
-        variant = json.load(variant_path.open())
-        try:
-            max_tau = variant['tdm_kwargs']['max_tau']
-            print("Max tau read from variant: {}".format(max_tau))
-        except KeyError:
-            print("Defaulting max tau to 0.")
-            max_tau = 0
-    else:
-        max_tau = args.mtau
-
-    env = data['env']
-    policy = data['policy']
-    policy.train(False)
-
-    if args.gpu:
-        ptu.set_gpu_mode(True)
-        policy.cuda()
-
-    while True:
-        paths = []
-        for _ in range(args.nrolls):
-            goal = env.sample_goal_for_rollout()
-            path = multitask_rollout(
-                env,
-                policy,
-                init_tau=max_tau,
-                goal=goal,
-                max_path_length=args.H,
-                animated=not args.hide,
-                cycle_tau=True,
-                decrement_tau=True,
-            )
-            paths.append(path)
-        env.log_diagnostics(paths)
-        for key, value in get_generic_path_information(paths).items():
-            logger.record_tabular(key, value)
-        logger.dump_tabular()
